{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regular_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZKukJx_2Kpj",
        "colab_type": "code",
        "outputId": "e750559d-eaaf-4e66-8fea-1846cb44dd27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "#Relevant Links\n",
        "#1. https://towardsdatascience.com/bert-classifier-just-another-pytorch-model-881b3cf05784\n",
        "!nvidia-smi\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Dec  8 04:18:38 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    31W / 250W |   8287MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpWg_DCjEpp3",
        "colab_type": "code",
        "outputId": "7a801683-c6fa-46c9-d015-a87057bb61e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        }
      },
      "source": [
        "! pip install constant\n",
        "!pip install bert-pytorch\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting constant\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/73/c272439718f93933e10da7e0502752b9c349c8bebe0ed2df14e618838bb7/constant-0.0.4.zip (63kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from constant) (2.10.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->constant) (1.1.1)\n",
            "Building wheels for collected packages: constant\n",
            "  Building wheel for constant (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for constant: filename=constant-0.0.4-cp36-none-any.whl size=73933 sha256=b6476e8f7dbfffcde5fd3d05534ee572bc0603f9314a2d8881ef3e701ed58f39\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/ef/ce/18966f544810076cef35c7a0e0eca464b9a3c070164a217f02\n",
            "Successfully built constant\n",
            "Installing collected packages: constant\n",
            "Successfully installed constant-0.0.4\n",
            "Collecting bert-pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/4d/328ca0670162d1a569854460cb1801e7e79f0e37238883cbd1d8c37cd6f4/bert_pytorch-0.0.1a4-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bert-pytorch) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-pytorch) (1.17.4)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from bert-pytorch) (1.3.1)\n",
            "Installing collected packages: bert-pytorch\n",
            "Successfully installed bert-pytorch-0.0.1a4\n",
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.7MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.32)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.32)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: regex, pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 regex-2019.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci2rw6qvDozu",
        "colab_type": "code",
        "outputId": "95d58a17-723c-4476-f58e-23ff99019509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "sys.path.append(os.path.join(os.path.dirname(sys.path[0]), 'analysis'))\n",
        "sys.path.append(os.path.join(os.path.dirname(os.path.dirname(sys.path[0])), 'configs' ))\n",
        "\n",
        "import constant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoiPduk2GfSo",
        "colab_type": "code",
        "outputId": "3d5560be-5093-4e3f-cad9-e5492b41a664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam, BertModel\n",
        "from pytorch_pretrained_bert import BertConfig\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6TTAVNku2Kc",
        "colab_type": "code",
        "outputId": "226b391f-b8f5-4ea0-b85e-726aba3f277b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#Data Reading\n",
        "# Mount drive for data reading\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/Shared drives/CIS 519 Project/Code/Dataset/Resampled4/\"\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj4bkVjlu8Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read full data path = \"/content/drive/Shared drives/CIS 519 Project/Code/Dataset/\"\n",
        "df_train_total = pd.read_csv(path + 'train.csv')\n",
        "df_val_total = pd.read_csv(path + 'validation.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwkdWl9Xu8O2",
        "colab_type": "code",
        "outputId": "82313c54-818c-46a4-8d06-16e3831f7cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        }
      },
      "source": [
        "df_train_total.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "      <th>homosexual_gay_or_lesbian</th>\n",
              "      <th>christian</th>\n",
              "      <th>jewish</th>\n",
              "      <th>muslim</th>\n",
              "      <th>black</th>\n",
              "      <th>white</th>\n",
              "      <th>psychiatric_or_mental_illness</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "      <th>created_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5367475</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>This is an insult to all immigrants who took t...</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-06-06 17:53:11.976493+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>389581</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>Eric, I was unaware that Obama had a line of p...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>2016-07-15 23:22:57.603863+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>259203</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>\"malign her character because of alleged illeg...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>2016-03-26 19:14:41.102508+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6274158</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Couldn't agree more with your last sentence, E...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-11-02 15:49:53.222384+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5435081</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>The liberal, married, gay Black woman who took...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-06-18 13:26:29.297687+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5693877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Get over it, two men took to the ring and one ...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-08-01 02:59:30.400500+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5801144</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>Yes, yes, it's \"The Media\" who forced Trump to...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-08-19 16:02:37.201001+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5078252</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>\"cannon fodder\" - they are \"acceptable losses\"...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-03-31 18:03:36.139268+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5277082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>No, not who cares, as in who cares, rather htt...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-05-19 14:33:37.520110+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>489731</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>The hate of white males from the progressive p...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>2016-09-24 04:44:47.907794+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id    target  ... toxicity_annotator_count                   created_date\n",
              "0  5367475  0.500000  ...                       10  2017-06-06 17:53:11.976493+00\n",
              "1   389581  0.166667  ...                        6  2016-07-15 23:22:57.603863+00\n",
              "2   259203  0.600000  ...                       10  2016-03-26 19:14:41.102508+00\n",
              "3  6274158  0.000000  ...                        4  2017-11-02 15:49:53.222384+00\n",
              "4  5435081  0.500000  ...                       10  2017-06-18 13:26:29.297687+00\n",
              "5  5693877  0.000000  ...                        4  2017-08-01 02:59:30.400500+00\n",
              "6  5801144  0.600000  ...                       10  2017-08-19 16:02:37.201001+00\n",
              "7  5078252  0.500000  ...                       10  2017-03-31 18:03:36.139268+00\n",
              "8  5277082  0.000000  ...                        4  2017-05-19 14:33:37.520110+00\n",
              "9   489731  0.828571  ...                       70  2016-09-24 04:44:47.907794+00\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7fHVdLas2hu",
        "colab_type": "code",
        "outputId": "9359e0fc-58d6-49bf-83a8-ec09108010d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        }
      },
      "source": [
        "df_val_total.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "      <th>homosexual_gay_or_lesbian</th>\n",
              "      <th>christian</th>\n",
              "      <th>jewish</th>\n",
              "      <th>muslim</th>\n",
              "      <th>black</th>\n",
              "      <th>white</th>\n",
              "      <th>psychiatric_or_mental_illness</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "      <th>created_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>299192</td>\n",
              "      <td>0.20</td>\n",
              "      <td>I'm pretty sure there's a difference as wide a...</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>2016-04-30 04:19:50.280309+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6157777</td>\n",
              "      <td>0.70</td>\n",
              "      <td>5 years as a prisoner of the Taliban? Lol, the...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-10-16 18:44:33.103845+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>398687</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Re: the caption. \"Man wire?\" I think the write...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2016-07-23 16:19:51.090606+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>742714</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Muslims in London want to build Europe's large...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2016-12-22 16:01:05.804576+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>927856</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Having been involved with a couple of people w...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-01-31 17:59:56.276643+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6294071</td>\n",
              "      <td>0.00</td>\n",
              "      <td>I think everyone is being way too harsh.  Spac...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-11-05 18:06:13.609132+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>514611</td>\n",
              "      <td>0.75</td>\n",
              "      <td>Let's get something straight, skippy, bragging...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>2016-10-08 05:12:23.719260+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>894593</td>\n",
              "      <td>0.50</td>\n",
              "      <td>Did we really need another instalment in the \"...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>2017-01-25 11:54:20.923911+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5675570</td>\n",
              "      <td>0.00</td>\n",
              "      <td>These games are a great and worthwhile initiat...</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-07-28 14:44:57.353013+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>884943</td>\n",
              "      <td>0.00</td>\n",
              "      <td>You didn't bother to read this did you?  The j...</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-01-23 17:53:51.510851+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  target  ... toxicity_annotator_count                   created_date\n",
              "0   299192    0.20  ...                       10  2016-04-30 04:19:50.280309+00\n",
              "1  6157777    0.70  ...                       10  2017-10-16 18:44:33.103845+00\n",
              "2   398687    0.00  ...                        4  2016-07-23 16:19:51.090606+00\n",
              "3   742714    0.00  ...                        4  2016-12-22 16:01:05.804576+00\n",
              "4   927856    0.00  ...                        4  2017-01-31 17:59:56.276643+00\n",
              "5  6294071    0.00  ...                        4  2017-11-05 18:06:13.609132+00\n",
              "6   514611    0.75  ...                       80  2016-10-08 05:12:23.719260+00\n",
              "7   894593    0.50  ...                       10  2017-01-25 11:54:20.923911+00\n",
              "8  5675570    0.00  ...                        4  2017-07-28 14:44:57.353013+00\n",
              "9   884943    0.00  ...                        4  2017-01-23 17:53:51.510851+00\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSGr1TEOu8SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# comments = pd.DataFrame(df.comment_text)\n",
        "# #comments.to_csv(path + \"only_comments.csv\")\n",
        "# comments_text = df.comment_text\n",
        "# df_store = df.copy()\n",
        "# comments_store = comments.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udi8XjuExtPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train_total#.sample(5000)\n",
        "df_val = df_val_total#.sample(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0glp8vl8s0WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comments_train = df_train.comment_text\n",
        "comments_val = df_val.comment_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_0vTV0tvG6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate protected attribute - gender\n",
        "def extract_female_gender(x):\n",
        "  if np.isnan(x.female) or x.female < 0.5:\n",
        "      return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8946xw4GTSsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate unprotected attribute labels\n",
        "def get_unprotected_class(list_of_protected):\n",
        "  new = [1 if i == 0 else 0 for i in list_of_protected]\n",
        "  return new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnWIvZxmvG86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate metrics\n",
        "def get_metrics(labels, preds):\n",
        "  pred_flat = preds.flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "\n",
        "  acc = accuracy_score(labels_flat, pred_flat)\n",
        "  pre = precision_score(labels_flat, pred_flat)\n",
        "  rec = recall_score(labels_flat, pred_flat)\n",
        "  f1 = f1_score(labels_flat, pred_flat, average=\"weighted\")\n",
        "\n",
        "  return acc, pre, rec, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LInCuFiEvG_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate labels\n",
        "toxicity_labels_train = list(df_train.target.apply(lambda x: 1 if x >= 0.5 else 0))\n",
        "identity_labels_train = list(df_train.apply(extract_female_gender, axis = 1))\n",
        "toxicity_labels_val = list(df_val.target.apply(lambda x: 1 if x >= 0.5 else 0))\n",
        "identity_labels_val = list(df_val.apply(extract_female_gender, axis = 1))\n",
        "unprotected_labels_train = get_unprotected_class(identity_labels_train)\n",
        "unprotected_labels_val = get_unprotected_class(identity_labels_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj7CCUdFvHCt",
        "colab_type": "code",
        "outputId": "90a77e81-686a-4a36-d22b-b1d06e54f270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "print(len(comments_train), len(toxicity_labels_train))\n",
        "print(comments_train[:10])\n",
        "print(toxicity_labels_train[:10])\n",
        "print(identity_labels_train[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10974 10974\n",
            "0    This is an insult to all immigrants who took t...\n",
            "1    Eric, I was unaware that Obama had a line of p...\n",
            "2    \"malign her character because of alleged illeg...\n",
            "3    Couldn't agree more with your last sentence, E...\n",
            "4    The liberal, married, gay Black woman who took...\n",
            "5    Get over it, two men took to the ring and one ...\n",
            "6    Yes, yes, it's \"The Media\" who forced Trump to...\n",
            "7    \"cannon fodder\" - they are \"acceptable losses\"...\n",
            "8    No, not who cares, as in who cares, rather htt...\n",
            "9    The hate of white males from the progressive p...\n",
            "Name: comment_text, dtype: object\n",
            "[1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n",
            "[1, 0, 1, 0, 1, 0, 1, 1, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfjrbmoUvcQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 128\n",
        "SEED = 519\n",
        "BATCH_SIZE = 32\n",
        "BERT_MODEL_PATH = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_3512JxvcUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_lines(example, max_seq_length,tokenizer):\n",
        "    #max_seq_length -=2\n",
        "    all_tokens = []\n",
        "    longer = 0\n",
        "    for text in tqdm(example):\n",
        "        tokens_a = tokenizer.tokenize(text)\n",
        "        if len(tokens_a)>max_seq_length:\n",
        "            tokens_a = tokens_a[:max_seq_length]\n",
        "            longer += 1\n",
        "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
        "        all_tokens.append(one_token)\n",
        "    print(\"Tokens longer than max_length: \", longer)\n",
        "    return np.array(all_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM1WMxLVvcXt",
        "colab_type": "code",
        "outputId": "9e5ddf5d-75be-456a-8190-2eb7034733cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#Prepare data\n",
        "input_train = convert_lines(comments_train.fillna(\"DUMMY_VALUE\"), MAX_SEQUENCE_LENGTH, tokenizer)\n",
        "toxicity_labels_train = torch.tensor(toxicity_labels_train)\n",
        "female_labels_train = torch.tensor(identity_labels_train)\n",
        "\n",
        "input_val = convert_lines(comments_val.fillna(\"DUMMY_VALUE\"), MAX_SEQUENCE_LENGTH, tokenizer)\n",
        "toxicity_labels_val = torch.tensor(toxicity_labels_val)\n",
        "female_labels_val = torch.tensor(identity_labels_val)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10974/10974 [00:11<00:00, 971.17it/s]\n",
            "  4%|▍         | 88/2000 [00:00<00:02, 876.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokens longer than max_length:  2690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [00:02<00:00, 920.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tokens longer than max_length:  544\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G20XIBVr-FkQ",
        "colab_type": "code",
        "outputId": "e6fedc6d-4c2d-4020-e89f-6c5c4f4adf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(torch.sum(toxicity_labels_val).data)\n",
        "print(torch.sum(female_labels_val).data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(338)\n",
            "tensor(1144)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdtIA_d27sqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Loader\n",
        "X_train = torch.utils.data.TensorDataset(torch.tensor(input_train, dtype=torch.long), toxicity_labels_train, female_labels_train)\n",
        "train_loader = torch.utils.data.DataLoader(X_train, batch_size=32, shuffle=True)\n",
        "#tk0 = tqdm(train_loader)\n",
        "\n",
        "X_val = torch.utils.data.TensorDataset(torch.tensor(input_val, dtype=torch.long), toxicity_labels_val, female_labels_val)\n",
        "val_loader = torch.utils.data.DataLoader(X_val, batch_size=32, shuffle=True)\n",
        "#vk0 = tqdm(val_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxBq_i9YtpZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FAIRNESS METRICS FUNCTION\n",
        "\n",
        "def get_fairness_metrics(actual_labels, y_pred, protected_labels, non_protected_labels, thres):\n",
        "\n",
        "  def get_toxicity_rates(y_pred, protected_labels, non_protected_labels, thres):\n",
        "    protected_ops = y_pred[protected_labels == 1]\n",
        "    protected_prob = sum(protected_ops)/len(protected_ops)\n",
        "\n",
        "    non_protected_ops = y_pred[non_protected_labels == 1]\n",
        "    non_protected_prob = sum(non_protected_ops)/len(non_protected_ops)\n",
        "\n",
        "    return np.round(protected_prob, 2), np.round(non_protected_prob, 2)\n",
        "\n",
        "  def get_true_positive_rates(actual_labels, y_pred, protected_labels, non_protected_labels, thres):\n",
        "\n",
        "    protected_ops = y_pred[np.bitwise_and(protected_labels == 1, actual_labels == 1)]\n",
        "    protected_prob = sum(protected_ops)/len(protected_ops)\n",
        "\n",
        "    non_protected_ops = y_pred[np.bitwise_and(non_protected_labels == 1, actual_labels == 1)]\n",
        "    non_protected_prob = sum(non_protected_ops)/len(non_protected_ops)\n",
        "\n",
        "    return np.round(protected_prob, 2), np.round(non_protected_prob, 2)\n",
        "\n",
        "\n",
        "  def get_false_positive_rates(actual_labels, y_pred, protected_labels, non_protected_labels, thres):\n",
        "\n",
        "    protected_ops = y_pred[np.bitwise_and(protected_labels == 1, actual_labels ==0)]\n",
        "    protected_prob = sum(protected_ops)/len(protected_ops)\n",
        "\n",
        "    non_protected_ops = y_pred[np.bitwise_and(non_protected_labels == 1, actual_labels == 0)]\n",
        "    non_protected_prob = sum(non_protected_ops)/len(non_protected_ops)\n",
        "\n",
        "    return np.round(protected_prob, 2), np.round(non_protected_prob, 2)\n",
        "\n",
        "  def demographic_parity(y_pred, protected_labels, non_protected_labels, thres):\n",
        "\n",
        "    protected_ops = y_pred[protected_labels == 1]\n",
        "    protected_prob = sum(protected_ops)/len(protected_ops)\n",
        "\n",
        "    non_protected_ops = y_pred[non_protected_labels == 1]\n",
        "    non_protected_prob = sum(non_protected_ops)/len(non_protected_ops)\n",
        "\n",
        "    return abs(protected_prob - non_protected_prob) #later take absolute diff - but we want to show females predicted more toxic than male\n",
        "\n",
        "  # | P_female(C = 1| Y = 1) - P_male(C = 1 | Y = 1) | < thres\n",
        "  def true_positive_parity(actual_labels, y_pred, protected_labels, non_protected_labels, thres):\n",
        "\n",
        "    protected_ops = y_pred[np.bitwise_and(protected_labels == 1, actual_labels == 1)]\n",
        "    protected_prob = sum(protected_ops)/len(protected_ops)\n",
        "\n",
        "    non_protected_ops = y_pred[np.bitwise_and(non_protected_labels == 1, actual_labels == 1)]\n",
        "    non_protected_prob = sum(non_protected_ops)/len(non_protected_ops)\n",
        "\n",
        "    return abs(protected_prob - non_protected_prob) #later take absolute diff - but we want to show females predicted more toxic than male\n",
        "\n",
        "  # | P_female(C = 1| Y = 0) - P_male(C = 1 | Y = 0) | < thres\n",
        "  def false_positive_parity(actual_labels, y_pred, protected_labels, non_protected_labels, thres):\n",
        "\n",
        "    protected_ops = y_pred[np.bitwise_and(protected_labels == 1, actual_labels ==0)]\n",
        "    protected_prob = sum(protected_ops)/len(protected_ops)\n",
        "\n",
        "    non_protected_ops = y_pred[np.bitwise_and(non_protected_labels == 1, actual_labels == 0)]\n",
        "    non_protected_prob = sum(non_protected_ops)/len(non_protected_ops)\n",
        "\n",
        "    return abs(protected_prob - non_protected_prob) #later take absolute diff - but we want to show females predicted more toxic than male\n",
        "\n",
        "\n",
        "  # Satisfy both true positive parity and false positive parity\n",
        "  def equalized_odds(actual_labels, y_pred, protected_labels, non_protected_labels, thres):\n",
        "    return true_positive_parity(actual_labels, y_pred, protected_labels, non_protected_labels, thres) + false_positive_parity(actual_labels, y_pred, protected_labels, non_protected_labels, thres)\n",
        "\n",
        "  female_tox_rate, nf_tox_rate = get_toxicity_rates(y_pred, protected_labels, non_protected_labels, thres)\n",
        "  female_tp_rate, nf_tp_rate = get_true_positive_rates(actual_labels, y_pred, protected_labels, non_protected_labels, thres)\n",
        "  female_fp_rate, nf_fp_rate = get_false_positive_rates(actual_labels, y_pred, protected_labels, non_protected_labels, thres)\n",
        "  demo_parity = demographic_parity(y_pred, protected_labels, non_protected_labels, thres)\n",
        "  tp_parity = true_positive_parity(actual_labels, y_pred, protected_labels, non_protected_labels, thres)\n",
        "  fp_parity = false_positive_parity(actual_labels, y_pred, protected_labels, non_protected_labels, thres)\n",
        "  equ_odds = equalized_odds(actual_labels, y_pred, protected_labels, non_protected_labels, thres)\n",
        "\n",
        "  return female_tox_rate, nf_tox_rate, female_tp_rate, nf_tp_rate, female_fp_rate, nf_fp_rate, demo_parity, tp_parity, fp_parity, equ_odds\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aep4ZvAKvHFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "UnfairClassifier - BERT  - PyTorch Implementation\n",
        "\"\"\"\n",
        "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072, \n",
        "        hidden_dropout_prob=0.1)\n",
        "\n",
        "class Regular_Classifier(nn.Module):\n",
        "    def __init__(self, toxicity_labels = 2):\n",
        "        super(Regular_Classifier, self).__init__()\n",
        "        \n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.c1 = nn.Linear(config.hidden_size, 324)\n",
        "        #self.c2 = nn.Linear(config.intermediate_size, 324)\n",
        "        self.c3 = nn.Linear(324, 2)\n",
        "\n",
        "        nn.init.xavier_normal_(self.c1.weight)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "\n",
        "        \n",
        "        #BERT\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "        # Classifier\n",
        "        classifier = F.relu(self.c1(pooled_output))\n",
        "        #classifier = F.relu(self.c2(classifier))\n",
        "        classifier_output = self.c3(classifier)\n",
        "\n",
        "\n",
        "        return classifier_output\n",
        "\n",
        "net = Regular_Classifier(toxicity_labels = 2) # instantiate the nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzpkhhwCeZso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conduct_validation(net, data_loader, adv = False):\n",
        "\n",
        "    eval_loss, eval_accuracy, eval_precision, eval_recall, eval_f1 = 0, 0, 0, 0, 0\n",
        "    nb_eval_steps = 0\n",
        "    \n",
        "    predictions_net = np.empty((0,))\n",
        "    truths = np.empty((0,))\n",
        "    identities = np.empty((0,))\n",
        "    correct_net = 0\n",
        "    total = 0\n",
        "\n",
        "    net.eval()\n",
        "    with torch.no_grad(): # IMPORTANT: we don't want to do back prop during validation/testing!\n",
        "      for index, data in enumerate(data_loader):\n",
        "\n",
        "        text, toxic_truth, female_truth = data\n",
        "\n",
        "        text = text.to(device)\n",
        "        toxic_truth = toxic_truth.to(device)\n",
        "        female_truth = female_truth.to(device)\n",
        "\n",
        "        if adv:\n",
        "          net_outputs, net_prev_outputs = net(text)\n",
        "        else:\n",
        "          net_outputs = net(text)\n",
        "        _, net_predicted = torch.max(net_outputs.data, 1)\n",
        "\n",
        "        batch_size = toxic_truth.size(0)\n",
        "        total += batch_size\n",
        "        correct_net_batch = (net_predicted == toxic_truth).sum().item()\n",
        "        correct_net += correct_net_batch\n",
        "\n",
        "        \n",
        "        predictions_net = np.concatenate((predictions_net, net_predicted.cpu().numpy()))\n",
        "        truths = np.concatenate((truths, toxic_truth.cpu().numpy()))\n",
        "        identities = np.concatenate((identities, female_truth.cpu().numpy()))\n",
        "\n",
        "        pred = net_predicted.detach().cpu().numpy()\n",
        "        label_ids = toxic_truth.to('cpu').numpy()\n",
        "\n",
        "        tmp_eval_accuracy, tmp_eval_precision, temp_eval_recall, tmp_eval_f1 = get_metrics(label_ids, pred)\n",
        "\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        eval_precision += tmp_eval_precision\n",
        "        eval_recall += temp_eval_recall\n",
        "        eval_f1 += tmp_eval_f1\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    f1_score = eval_f1/nb_eval_steps\n",
        "    prec_score = eval_precision/nb_eval_steps\n",
        "    recall_score = eval_recall/nb_eval_steps\n",
        "    acc_score = eval_accuracy/nb_eval_steps\n",
        "\n",
        "    print(\"F1 Score: \", f1_score)\n",
        "    print(\"Precision Score: \", prec_score)\n",
        "    print(\"Recall Score: \", recall_score)\n",
        "    print(\"Acc Score: \", acc_score, \"\\n\\n\")\n",
        "\n",
        "    net.train()\n",
        "    \n",
        "    return (predictions_net, truths, identities, acc_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdibxjMi7tEr",
        "colab_type": "code",
        "outputId": "e293ceb9-97d8-45b4-9b67-a5ff453fb3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### REGULAR CLASSIFIER\n",
        "\n",
        "lrlast = .001\n",
        "lrmain = .00001\n",
        "optimizer_net = optim.Adam(\n",
        "    [\n",
        "        {\"params\":net.bert.parameters(),\"lr\": lrmain},\n",
        "        {\"params\":net.c1.parameters(), \"lr\": lrlast},\n",
        "        #{\"params\":clf.c2.parameters(), \"lr\": lrlast},\n",
        "    {\"params\":net.c3.parameters(), \"lr\": lrlast}    \n",
        "  ])\n",
        "  \n",
        "\n",
        "loss_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Process\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "\n",
        "train_accs = []\n",
        "valid_accs = []\n",
        "\n",
        "n_epochs = 3\n",
        "\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "\n",
        "    running_net_loss = 0.0\n",
        "    \n",
        "    print('Epoch:' + str(epoch))\n",
        "\n",
        "    for i, data in enumerate(train_loader): # starting from the 0th batch\n",
        "        # get the inputs and labels\n",
        "        \n",
        "        inputs, toxicity_true, female_true = data\n",
        "        inputs = inputs.to(device)\n",
        "        toxicity_true = toxicity_true\n",
        "        female_true = female_true\n",
        "        #toxicity_true = torch.sparse.torch.eye(2).index_select(dim=0, index=toxicity_true) \n",
        "        #female_true = torch.sparse.torch.eye(2).index_select(dim=0, index=female_true) \n",
        "\n",
        "        #print(toxicity_true.dtype)\n",
        "\n",
        "        toxicity_true = toxicity_true.to(device)\n",
        "        female_true = female_true.to(device)\n",
        "\n",
        "\n",
        "        optimizer_net.zero_grad()\n",
        "\n",
        "        net_output = net(inputs)\n",
        "        net_loss = loss_criterion(net_output, toxicity_true) # compute loss\n",
        "        net_loss.backward()\n",
        "        optimizer_net.step()\n",
        "\n",
        "        running_net_loss += net_loss.item()\n",
        "\n",
        "        if i % 32 == 31:   \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_net_loss / 32))\n",
        "            \n",
        "            running_total_loss = 0.0\n",
        "            running_net_loss = 0.0\n",
        "\n",
        "\n",
        "    print('Training metrics:')\n",
        "    y_pred, actual_labels, protected_labels, acc_score = conduct_validation(net, train_loader, adv = None)\n",
        "    train_accs.append(acc_score)\n",
        "\n",
        "    print('Validation metrics:')\n",
        "    y_pred, actual_labels, protected_labels, acc_score = conduct_validation(net, val_loader, adv = None)\n",
        "    valid_accs.append(acc_score)\n",
        "\n",
        "    if epoch == n_epochs-1:\n",
        "\n",
        "      non_protected_labels = np.asarray(get_unprotected_class(protected_labels))\n",
        "      thres = 0.5\n",
        "      female_tox_rate, nf_tox_rate, female_tp_rate, nf_tp_rate, female_fp_rate, nf_fp_rate, demo_parity, tp_parity, fp_parity, equ_odds =\\\n",
        "       get_fairness_metrics(actual_labels, y_pred, protected_labels, non_protected_labels, thres)\n",
        "\n",
        "      print(\"Toxicity Prediction Rates: \", \"Female -\", female_tox_rate, \"Non-Female - \", nf_tox_rate)\n",
        "      print(\"True Positive Prediction Rates: \", \"Female -\", female_tp_rate, \"Non-Female - \", nf_tp_rate)\n",
        "      print(\"False Positive Prediction Rates: \", \"Female -\", female_fp_rate, \"Non-Female - \", nf_fp_rate)\n",
        "      print(\"Demographic Parity: \", demo_parity)\n",
        "      print(\"True Positive Parity: \", tp_parity)\n",
        "      print(\"False Positive Parity: \", fp_parity)\n",
        "      print(\"Equalized Odds: \", equ_odds)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0\n",
            "[1,    32] loss: 0.742\n",
            "[1,    64] loss: 0.698\n",
            "[1,    96] loss: 0.684\n",
            "[1,   128] loss: 0.683\n",
            "[1,   160] loss: 0.602\n",
            "[1,   192] loss: 0.506\n",
            "[1,   224] loss: 0.449\n",
            "[1,   256] loss: 0.466\n",
            "[1,   288] loss: 0.477\n",
            "[1,   320] loss: 0.412\n",
            "Training metrics:\n",
            "F1 Score:  0.8522093573614691\n",
            "Precision Score:  0.8379454678958149\n",
            "Recall Score:  0.8718289219548374\n",
            "Acc Score:  0.8522959183673469 \n",
            "\n",
            "\n",
            "Validation metrics:\n",
            "F1 Score:  0.7564512664169679\n",
            "Precision Score:  0.3581232609593954\n",
            "Recall Score:  0.828557685700543\n",
            "Acc Score:  0.7217261904761905 \n",
            "\n",
            "\n",
            "Epoch:1\n",
            "[2,    32] loss: 0.386\n",
            "[2,    64] loss: 0.337\n",
            "[2,    96] loss: 0.335\n",
            "[2,   128] loss: 0.357\n",
            "[2,   160] loss: 0.342\n",
            "[2,   192] loss: 0.331\n",
            "[2,   224] loss: 0.382\n",
            "[2,   256] loss: 0.365\n",
            "[2,   288] loss: 0.330\n",
            "[2,   320] loss: 0.334\n",
            "Training metrics:\n",
            "F1 Score:  0.8744975058548475\n",
            "Precision Score:  0.9484038529645497\n",
            "Recall Score:  0.7909610176886892\n",
            "Acc Score:  0.875522351797862 \n",
            "\n",
            "\n",
            "Validation metrics:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Score:  0.8512964875082815\n",
            "Precision Score:  0.5116991914610962\n",
            "Recall Score:  0.6294904830619117\n",
            "Acc Score:  0.84375 \n",
            "\n",
            "\n",
            "Epoch:2\n",
            "[3,    32] loss: 0.283\n",
            "[3,    64] loss: 0.296\n",
            "[3,    96] loss: 0.258\n",
            "[3,   128] loss: 0.263\n",
            "[3,   160] loss: 0.272\n",
            "[3,   192] loss: 0.248\n",
            "[3,   224] loss: 0.265\n",
            "[3,   256] loss: 0.286\n",
            "[3,   288] loss: 0.266\n",
            "[3,   320] loss: 0.262\n",
            "Training metrics:\n",
            "F1 Score:  0.9450966027614701\n",
            "Precision Score:  0.9545056111760863\n",
            "Recall Score:  0.9330901734420185\n",
            "Acc Score:  0.9450619533527697 \n",
            "\n",
            "\n",
            "Validation metrics:\n",
            "F1 Score:  0.8263218753192836\n",
            "Precision Score:  0.46213002165383105\n",
            "Recall Score:  0.7547871000251952\n",
            "Acc Score:  0.8060515873015873 \n",
            "\n",
            "\n",
            "Toxicity Prediction Rates:  Female - 0.35 Non-Female -  0.2\n",
            "True Positive Prediction Rates:  Female - 0.84 Non-Female -  0.65\n",
            "False Positive Prediction Rates:  Female - 0.25 Non-Female -  0.1\n",
            "Demographic Parity:  0.1490180380367296\n",
            "True Positive Parity:  0.18424306659600775\n",
            "False Positive Parity:  0.15353238096226957\n",
            "Equalized Odds:  0.3377754475582773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylQJoXhzzRdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), path + \"Final_Regular_Classifier\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBjNSSZR_pr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del net\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGOxkBh0293T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}